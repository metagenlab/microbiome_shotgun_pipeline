#ezVIR params
ezvir_db=config["ezvir_database"]
#Benchmark params
if paired:
    pairing=2
else:
    pairing=1
read_len=config["samples_read_length"]
superkingdom=config["superkingdom"]
rank=config["target_rank"]
community=config['community_name']
tools=sorted(list(config["tools"].keys()))
threshold=config["reads_threshold"]
clustering=config["clustering"]
distance=config["distance"]
metric=config["metric"]
#generate all tools taxonomy tables
rule all_tax:
    input: merged_tsv = expand("taxonomy-tables/all_tools/{tool}.tsv",tool=tools),
           status_update = "ete3-NCBI-database.txt",
           coverage = expand("taxonomy-tables/all_tools/{tool}-coverage.tsv",tool=tools)


#generate all tools outputs without a gold standard
rule all_tool_out:
    input: merged_tsv=expand("taxonomy-tables/all_tools/{tool}.tsv",tool=tools),
           barplots=expand(f"plots/{superkingdom}/barplot_{{variable}}_{rank}_level.pdf",variable=['tools','samples']),
           heatmap_counts=f"plots/{superkingdom}/heatmap_counts_{threshold}_{rank}_level.pdf",
           heatmap_presence_tools=f"plots/{superkingdom}/presence_between_tools_{rank}_level.pdf",
           heatmap_presence_samples=f"plots/{superkingdom}/presence_between_samples_{rank}_level.pdf",
           nmds=expand(f"plots/nmds-{{tool}}-{metric}-{rank}-level.png",tool=tools),
           clustermap=expand(f"plots/{{tool}}-{rank}-{clustering}-{distance}-heatmap.pdf",tool=tools),
           alpha=expand(f"plots/alpha-diversity-{{tool}}-{rank}-level.png",tool=tools),
           tab="benchmark/resources_usage/resources.tsv",
           memo="benchmark/resources_usage/memory.pdf",
           time="benchmark/resources_usage/time.pdf",
           mem_and_time="benchmark/resources_usage/mem-time.pdf",



#generate all benchmarks compared to a gold standard
rule all_benchmark:
    input:  merged_tsv=expand("taxonomy-tables/all_tools/{tool}.tsv",tool=tools),
            read_counts_heatmaps=f"plots/{superkingdom}/heatmap_counts_{threshold}_{rank}_level.pdf",
            gold_standard=f"gold_standard/gs_{community}.tsv",
            scores_presence=expand("benchmark/tax-class/{community}/stats/{superkingdom}/{out}_{rank}_level_{thr}.tsv",
                superkingdom=superkingdom,community=community,thr=threshold,out=['scores','presence'],rank=rank),
            presence_heatmap=f"benchmark/tax-class/{community}/plots/{superkingdom}/heatmap_presence_{threshold}_{rank}_level.pdf",
            pr_curve=f"benchmark/tax-class/{community}/plots/{superkingdom}/precision-recall-{rank}.pdf",
            f1_curve=f"benchmark/tax-class/{community}/plots/{superkingdom}/f1-scores-{rank}.pdf",
            curve_table=f"benchmark/tax-class/{community}/stats/{superkingdom}/precision-recall-{rank}.tsv",
            optimal_params=f"benchmark/tax-class/{community}/stats/{superkingdom}/optimal-params-{rank}.tsv",
            l1_distance=f"benchmark/tax-class/{community}/plots/{superkingdom}/l1-distance-{rank}.pdf",
            l1_dist_table=f"benchmark/tax-class/{community}/stats/l1-distance-{superkingdom}-{rank}.tsv",
            barplots=expand("plots/{superkingdom}/barplot_{variable}_{rank}_level.pdf",superkingdom=superkingdom,
                rank=rank,variable=['tools','samples']),
            all_barplots=f"benchmark/tax-class/{community}/plots/{superkingdom}/barplot-{rank}.pdf",
            table_reads=f"benchmark/tax-class/{community}/stats/{superkingdom}/classified-reads.tsv",
            barplot_reads=f"benchmark/tax-class/{community}/plots/{superkingdom}/classified-reads.pdf",
            tab="benchmark/resources_usage/resources.tsv",
            memo="benchmark/resources_usage/memory.pdf",
            time="benchmark/resources_usage/time.pdf",
            mem_and_time="benchmark/resources_usage/mem-time.pdf"


rule check_for_ete3_ncbi_database_update:
    conda: pipeline_path + "envs/benchmark.yml"

    output: temp("ete3-NCBI-database.txt")

    log: logging_folder + "benchmark/ete3-NCBI-database.log"

    script: "scripts/update-ete3.py"


rule get_prokaryotes_assemblies_summaries:
    output: "taxonomy-tables/prokaryotes.txt"

    shell:
        """
        wget ftp://ftp.ncbi.nlm.nih.gov/genomes/GENOME_REPORTS/prokaryotes.txt > {output[0]}
        """

rule get_eukaryotes_assemblies_summaries:
    output: "taxonomy-tables/eukaryotes.txt"

    shell:
        """
        wget https://ftp.ncbi.nlm.nih.gov/genomes/GENOME_REPORTS/eukaryotes.txt > {output[0]}
        """

rule get_viruses_assemblies_summaries:
    output: "taxonomy-tables/viruses.txt"

    shell:
        """
        wget https://ftp.ncbi.nlm.nih.gov/genomes/GENOME_REPORTS/viruses.txt > {output[0]}
        """

rule linear_tax_Kraken2:
    conda: pipeline_path + "envs/benchmark.yml"

    input: tax="kraken2/{sample}/report.txt",
            sample_info='samples.tsv'

    output: "taxonomy-tables/kraken2/{sample}.tsv"

    params: NCBI_email=config['email'],
            NCBI_key=config['api_key']

    resources: ncbi_requests=1

    log: logging_folder + "taxonomy-tables/kraken2/{sample}.log"

    script: "scripts/kraken2-tax.py"


rule linear_tax_Kraken2X:
    conda: pipeline_path + "envs/benchmark.yml"

    input: tax="kraken2x/{sample}/report.txt",
            sample_info='samples.tsv'

    output: "taxonomy-tables/kraken2x/{sample}.tsv"

    params: NCBI_email=config['email'],
            NCBI_key=config['api_key']

    script: "scripts/kraken2-tax.py"


rule linear_tax_Bracken:
    conda: pipeline_path + "envs/benchmark.yml"

    input: "kraken2/{sample}/bracken.txt"

    output: "taxonomy-tables/bracken/{sample}.tsv"

    script: "scripts/bracken-tax.py"


rule correct_Pathseq_counts:
    conda: pipeline_path + "envs/benchmark.yml"

    input: "Pathseq/{sample}/output/scores.txt"

    output: "Pathseq/{sample}/output/correct-scores.txt"

    script: "scripts/pathseq-correct-counts.py"


rule linear_tax_Pathseq:
    conda: pipeline_path + "envs/benchmark.yml"

    input: "Pathseq/{sample}/output/correct-scores.txt"

    output: "taxonomy-tables/pathseq/{sample}.tsv"

    script: "scripts/pathseq-tax.py"


rule linear_tax_Kaiju:
    conda: pipeline_path + "envs/benchmark.yml"

    input: "kaiju/{sample}/summary.tsv"

    output: "taxonomy-tables/kaiju/{sample}.tsv"

    script: "scripts/kaiju-tax.py"


rule linear_tax_SURPI:
    conda: pipeline_path + "envs/benchmark.yml"

    input: bac="SURPI/{sample}/OUTPUT_{sample}/{sample}.NT.snap.matched.d1.fl.Bacteria.annotated.species.clx.counttable",
           vir="SURPI/{sample}/OUTPUT_{sample}/{sample}.NT.snap.matched.d16.fl.Viruses.filt.NTblastn_tru.dust.annotated.species.clx.counttable"
            #dust.annotated file because low complexity regions are substracted

    output: "taxonomy-tables/surpi/{sample}.tsv"

    log: logging_folder + f"benchmark/{community}/classification/{{sample}}-surpi.log"

    script: "scripts/surpi-tax.py"



rule linear_tax_ezVIR:
    conda: pipeline_path + "envs/benchmark.yml"

    input: hits="ezVIR/{sample}/report/ALL-RESULTS.ezv"


    output: "taxonomy-tables/ezvir/{sample}.tsv"

    params: read_len=config["samples_read_length"],
            gen_taxids=f'{ezvir_db}/genome_taxids.csv'

    script: "scripts/ezVIR-tax.py"


rule linear_tax_ganon:
    conda: pipeline_path + "envs/benchmark.yml"

    input: "ganon/{sample}/classified.rep"

    output: "taxonomy-tables/ganon/{sample}.tsv"

    params: NCBI_email=config['email'],
            NCBI_key=config['api_key']

    script: "scripts/ganon-tax.py"


rule linear_tax_centrifuge:
    conda: pipeline_path + "envs/benchmark.yml"

    input: tax="centrifuge/{sample}/centrifuge-k-report.txt",
           sample_info='samples.tsv',
           update="ete3-NCBI-database.txt"

    output: "taxonomy-tables/centrifuge/{sample}.tsv"

    resources: ncbi_requests=1

    params: NCBI_email=config['email'],
            NCBI_key=config['api_key']

    log: logging_folder + "taxonomy-tables/centrifuge/{sample}.log"

    script: "scripts/kraken2-tax.py"


rule linear_tax_metaphlan:
    conda: pipeline_path + "envs/benchmark.yml"

    input: "metaphlan/{sample}/profiled_{sample}.tsv"

    output: "taxonomy-tables/metaphlan/{sample}.tsv"

    params: NCBI_email=config['email'],
            NCBI_key=config['api_key']

    script: "scripts/metaphlan-tax.py"



rule linear_tax_motus:
    conda: pipeline_path + "envs/benchmark.yml"

    input: "motus/{sample}/profiled_{sample}.tsv"

    output: "taxonomy-tables/motus/{sample}.tsv"

    params: NCBI_email=config['email'],
            NCBI_key=config['api_key']

    script: "scripts/motus-tax.py"



rule merge_all_tools_out:
    input: expand("taxonomy-tables/{{tool}}/{sample}.tsv",sample=list(read_naming.keys()))

    output: "taxonomy-tables/all_tools/{tool}.tsv"

    script: "scripts/cat-tax.py"


rule calculate_coverage:
    input: tab="taxonomy-tables/{tool}/{sample}.tsv",
           prok="taxonomy-tables/prokaryotes.txt",
           euk='taxonomy-tables/eukaryotes.txt',
           vir='taxonomy-tables/viruses.txt'

    output: "taxonomy-tables/{tool}/{sample}.cov"

    params: rank=rank,
            pairing=pairing,
            readlen=read_len

    script: "scripts/normalize.py"

rule concat_coverages_samples:
    input: expand("taxonomy-tables/{tool}/{sample}.cov",sample=list(read_naming.keys()),tool=tools)

    output: "taxonomy-tables/all_tools/{tool}-coverage.tsv"

    script: "scripts/cat-tax.py"

rule clustermap_samples:
    conda: pipeline_path + "envs/benchmark.yml"

    input: "taxonomy-tables/all_tools/{tool}.tsv"

    output: plot=f"plots/{{tool}}-{rank}-{clustering}-{distance}-heatmap.pdf",
            read_counts="plots/{tool}-read_counts.csv",
            metadata="plots/{tool}-metadata.csv"

    params: rank=rank,
            clustering=clustering,
            distance=distance

    script: "scripts/clustermap.py"

rule plot_nmds:
    conda: pipeline_path + "envs/nmds.yml"

    input: read_counts="plots/{tool}-read_counts.csv",
           metadata="plots/{tool}-metadata.csv"

    output: nmds=f"plots/nmds-{{tool}}-{metric}-{rank}-level.png"

    params: metric=config["metric"]

    log: f"plots/nmds-{{tool}}-{rank}-level.txt"

    script: "scripts/NMDS.R"

rule alpha_diversity:
    conda: pipeline_path + "envs/nmds.yml"

    input: read_counts="plots/{tool}-read_counts.csv",
           metadata="plots/{tool}-metadata.csv"

    output: alpha_cor=f"plots/alpha-diversity-{{tool}}-{rank}-level.png"

    params: config["cor"]

    script: "scripts/alpha.R"


rule plot_tools_output:
    conda: pipeline_path + "envs/benchmark.yml"

    input: expand("taxonomy-tables/{tool}/{sample}.tsv",tool=tools,sample=list(read_naming.keys()))

    output: barplot_samples=f"plots/{superkingdom}/barplot_samples_{rank}_level.pdf",
            barplot_tools=f"plots/{superkingdom}/barplot_tools_{rank}_level.pdf",
            heatmap_counts=f"plots/{superkingdom}/heatmap_counts_{threshold}_{rank}_level.pdf",
            heatmap_presence_tools=f"plots/{superkingdom}/presence_between_tools_{rank}_level.pdf",
            heatmap_presence_samples=f"plots/{superkingdom}/presence_between_samples_{rank}_level.pdf",

    params: rank=config["target_rank"],
            value=config["target_value"],
            superkingdom=superkingdom,
            threshold=threshold,
            matrix_path=f"plots/{superkingdom}"

    script: "scripts/visualize-tool-output.py"



rule plot_resource_usage:
    conda: pipeline_path + "envs/benchmark.yml"

    input: expand("benchmark/resources_usage/{sample}/{tool}.benchmark.txt",sample=list(read_naming.keys()),tool=tools)

    output: tab="benchmark/resources_usage/resources.tsv",
            memo="benchmark/resources_usage/memory.pdf",
            time="benchmark/resources_usage/time.pdf",
            mem_and_time="benchmark/resources_usage/mem-time.pdf"

    params: type=config["tools"]

    script: "scripts/resources-usage.py"



rule genereate_gold_standard_profile:
    conda: pipeline_path + "envs/benchmark.yml"

    input: f"gold_standard/{community}.tsv"

    output: f"gold_standard/gs_{community}.tsv"

    params: community=community

    script: "scripts/gold-standard-tax.py"



rule precision_recall_f1_score_per_tool:
    conda: pipeline_path + "envs/benchmark.yml"

    input: gold_standard=f"gold_standard/gs_{community}.tsv",
            tool_out="taxonomy-tables/all_tools/{tool}.tsv"

    output: scores=f"benchmark/tax-class/{community}/stats/{{tool}}/{superkingdom}_scores_{rank}_level_{threshold}.tsv",
            presence=f"benchmark/tax-class/{community}/stats/{{tool}}/{superkingdom}_presence_{rank}_level_{threshold}.tsv"

    params: threshold=threshold,
            superkingdom=superkingdom

    script: "scripts/stats.py"



rule regroup_scores_and_presence:
    conda: pipeline_path + "envs/benchmark.yml"

    input: scores=expand("benchmark/tax-class/{community}/stats/{tool}/{superkingdom}_scores_{rank}_level_{threshold}.tsv",community=community,tool=tools,superkingdom=superkingdom,rank=rank,threshold=threshold),
           presence=expand("benchmark/tax-class/{community}/stats/{tool}/{superkingdom}_presence_{rank}_level_{threshold}.tsv",community=community,tool=tools,superkingdom=superkingdom,rank=rank,threshold=threshold),

    output: all_scores=f"benchmark/tax-class/{community}/stats/{superkingdom}/scores_{rank}_level_{threshold}.tsv",
            all_presence=f"benchmark/tax-class/{community}/stats/{superkingdom}/presence_{rank}_level_{threshold}.tsv"

    script: "scripts/concat.py"


rule presence_heatmap:
    conda: pipeline_path + "envs/benchmark.yml"

    input: f"benchmark/tax-class/{community}/stats/{superkingdom}/presence_{rank}_level_{threshold}.tsv"

    output: f"benchmark/tax-class/{community}/plots/{superkingdom}/heatmap_presence_{threshold}_{rank}_level.pdf"

    params: rank=config["target_rank"]

    script: "scripts/heatmap-presence.py"



rule barplot_counts:
    conda: pipeline_path + "envs/benchmark.yml"

    input: gold_standard=f"gold_standard/gs_{community}.tsv",
           tool_out="taxonomy-tables/all_tools/{tool}.tsv"

    output: f"benchmark/tax-class/{community}/{{tool}}/{superkingdom}-barplot_{rank}_level.pdf"

    params: rank=config["target_rank"],
            superkingdom=superkingdom

    script: "scripts/barplot.py"



rule all_tools_barplot_counts:
    conda: pipeline_path + "envs/benchmark.yml"

    input: gold_standard=f"gold_standard/gs_{community}.tsv",
           tool_out=expand("taxonomy-tables/all_tools/{tool}.tsv",tool=tools)

    params: rank=config["target_rank"],
            superkingdom=superkingdom

    output: all_barplots=f"benchmark/tax-class/{community}/plots/{superkingdom}/barplot-{rank}.pdf"

    script: "scripts/multi-barplot.py"


rule l1_distance:
    conda: pipeline_path + "envs/benchmark.yml"

    input: gold_standard=f"gold_standard/gs_{community}.tsv",
            all_tools=expand("taxonomy-tables/all_tools/{tool}.tsv",tool=tools)

    output: l1_distance=f"benchmark/tax-class/{community}/plots/{superkingdom}/l1-distance-{rank}.pdf",
            l1_dist_table=f"benchmark/tax-class/{community}/stats/l1-distance-{superkingdom}-{rank}.tsv"

    params: rank=rank,
            superkingdom=superkingdom,
            type=config["tools"]

    script: "scripts/l1-distance.py"


rule get_precision_recall_table:
    conda: pipeline_path + "envs/benchmark.yml"

    input: gold_standard=f"gold_standard/gs_{community}.tsv",
           tool="taxonomy-tables/all_tools/{tool}.tsv"

    output: aupr_table=f"benchmark/tax-class/{community}/stats/{{tool}}/aupr-{superkingdom}-{rank}.tsv"

    params: rank=rank,
            superkingdom=superkingdom,
            read_step=config["read-step"],
            max_read=config["max-read"]

    script: "scripts/precision-recall.py"


rule plot_precision_recall_f1_curves:
   conda: pipeline_path + "envs/benchmark.yml"

   input: expand("benchmark/tax-class/{community}/stats/{tool}/aupr-{superkingdom}-{rank}.tsv",superkingdom=superkingdom,community=community,tool=tools,rank=rank)

   output:  pr_curve=f"benchmark/tax-class/{community}/plots/{superkingdom}/precision-recall-{rank}.pdf",
            f1_curve=f"benchmark/tax-class/{community}/plots/{superkingdom}/f1-scores-{rank}.pdf",
            curve_table=f"benchmark/tax-class/{community}/stats/{superkingdom}/precision-recall-{rank}.tsv",
            optimal_params=f"benchmark/tax-class/{community}/stats/{superkingdom}/optimal-params-{rank}.tsv"

   script: "scripts/plot-precision-recall.py"


rule number_of_classified_reads:
    conda: pipeline_path + "envs/benchmark.yml"

    input: gold_standard=f"gold_standard/gs_{community}.tsv",
           all_tools=expand("taxonomy-tables/all_tools/{tool}.tsv",tool=tools)

    output: table=f"benchmark/tax-class/{community}/stats/{superkingdom}/classified-reads.tsv",
            barplot=f"benchmark/tax-class/{community}/plots/{superkingdom}/classified-reads.pdf"

    params: superkingdom=superkingdom

    script: "scripts/classified-reads.py"



if community=='qPCR':

    rule all_PCR:
        input: all_scores=f"benchmark/tax-class/{community}/stats/{superkingdom}/PCR_scores-{threshold}.tsv",
                all_presence=f"benchmark/tax-class/{community}/stats/{superkingdom}/PCR_presence-{threshold}.tsv"

    rule precision_recall_vs_qPCR:
        conda: pipeline_path + "envs/benchmark.yml"

        input: gold_standard=f"gold_standard/gs_{community}.tsv",
                tool_out="taxonomy-tables/all_tools/{tool}.tsv"

        output: scores=f"benchmark/tax-class/{community}/stats/{{tool}}/PCR_{superkingdom}_scores-{threshold}.tsv",
                presence=f"benchmark/tax-class/{community}/stats/{{tool}}/PCR_{superkingdom}_presence-{threshold}.tsv"

        params: threshold=threshold,
                superkingdom=superkingdom

        script: "scripts/qPCR.py"

    rule concat_qPCR_results:
        conda: pipeline_path + "envs/benchmark.yml"

        input: scores=expand("benchmark/tax-class/{community}/stats/{tool}/PCR_{superkingdom}_scores-{threshold}.tsv",superkingdom=superkingdom,community=community,tool=tools,threshold=threshold),
               presence=expand("benchmark/tax-class/{community}/stats/{tool}/PCR_{superkingdom}_presence-{threshold}.tsv",superkingdom=superkingdom,community=community,tool=tools,threshold=threshold)

        output: all_scores=f"benchmark/tax-class/{community}/stats/{superkingdom}/PCR_scores-{threshold}.tsv",
                all_presence=f"benchmark/tax-class/{community}/stats/{superkingdom}/PCR_presence-{threshold}.tsv"

        script: "scripts/concat.py"
