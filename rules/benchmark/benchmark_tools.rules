#setup all tools native database
ezvir_db=config["ezvir_database"]
surpi_db=config["surpi_database"]
pathseq_db=config["pathseq_database"]
kraken_db_path=config["kraken_database"]
ganon_db_path=config["ganon_db_path"]

read_len=config["samples_read_length"]
kmer_len=config["kraken_kmer_len"]

rule all_database_setup:
    input: surpi_db=f"{surpi_db}/build/nt_curated.fa",
           pathseq_host_fai=f"{pathseq_db}/pathseq_host.fa.fai",
           pathseq_host_fa=f"{pathseq_db}/pathseq_host.fa",
           pathseq_host_bfi=f"{pathseq_db}/pathseq_host.bfi",
           pathseq_host_img=f"{pathseq_db}/pathseq_host.fa.img",
           pathseq_host_dict=f"{pathseq_db}/pathseq_host.dict",
           pathseq_fai=f"{pathseq_db}/pathseq_microbe.fa.fai",
           pathseq_fa=f"{pathseq_db}/pathseq_microbe.fa",
           pathseq_img=f"{pathseq_db}/pathseq_microbe.fa.img",
           pathseq_dict=f"{pathseq_db}/pathseq_microbe.dict",
           pathseq_tax=f"{pathseq_db}/pathseq_taxonomy.db",
           kraken2_tax=f"{kraken_db_path}/taxo.k2d",
           kraken2_names=f"{kraken_db_path}/taxonomy/names.dmp",
           kraken2_nodes=f"{kraken_db_path}/taxonomy/nodes.dmp",
           kraken2_univec=f"{kraken_db_path}/library/UniVec_Core/library.fna",
           kraken2_human=f"{kraken_db_path}/library/human/library.fna",
           kraken2_viral=f"{kraken_db_path}/library/viral/library.fna",
           kraken2_bacteria=f"{kraken_db_path}/library/bacteria/library.fna",
           kraken2_archea=f"{kraken_db_path}/library/archaea/library.fna",
           bracken=f"{kraken_db_path}/database{read_len}mers.kmer_distrib",
           ganon_dl=f"{ganon_db_path}/refseqCG/assemblies/updated_sequence_accession.txt",
           ganon_filter=f"{ganon_db_path}/refseqCG/refseqCG.filter",
           ganon_fna=f"{ganon_db_path}/refseqCG/refseqCG.fna",
           ganon_names=f"{ganon_db_path}/refseqCG/assemblies/names.dmp",
           ganon_nodes=f"{ganon_db_path}/refseqCG/assemblies/nodes.dmp",
           ganon_merged=f"{ganon_db_path}/refseqCG/assemblies/merged.dmp",
           ganon_seq_info=f"{ganon_db_path}/refseqCG/assemblies/acc_len_taxid.txt",
           ezVIR_index=f"{ezvir_db}/EZV0.1-database.rev.2.bt2",
           ezVIR_len=f"{ezvir_db}/genome_lengths.csv",
           ezVIR_names=f"{ezvir_db}/genome_names.csv",
           ezVIR_taxids=f"{ezvir_db}/genome_taxids.csv",
           ezVIR_colours=f"{ezvir_db}/colours.csv"


superkingdom=config["superkingdom"]
rank=config["target_rank"]
community=config['community_name']
tools=sorted(list(config["tools"].keys()))
threshold=config["reads_threshold"]

#generate all tools taxonomy tables
rule all_tax:
    input: merged_tsv=expand("taxonomy-tables/{tool}.tsv",tool=tools)

#generate all tools outputs without a gold standard
rule all_tool_out:
    input: merged_tsv=expand("taxonomy-tables/{tool}.tsv",tool=tools),
           heatmap_per_sample=expand("{tool}/heatmap-{superkingdom}-{rank}-level.pdf",superkingdom=superkingdom,rank=rank,tool=tools),
           barplots=expand("plots/{superkingdom}/barplot_{variable}_{rank}_level.pdf",superkingdom=superkingdom,rank=rank,variable=['tools','samples']),
           heatmap_counts=f"plots/{superkingdom}/heatmap_counts_{threshold}_{rank}_level.pdf",
           heatmap_presence=f"plots/{superkingdom}/heatmap_presence_{rank}_level.pdf",
           tab="benchmark/resources_usage/resources.tsv",
           memo="benchmark/resources_usage/memory.pdf",
           time="benchmark/resources_usage/time.pdf",
           mem_and_time="benchmark/resources_usage/mem-time.pdf"


#generate all benchmarks compared to a gold standard
rule all_benchmark:
    input:  merged_tsv=expand("taxonomy-tables/{tool}.tsv",tool=tools),
            read_counts_heatmaps=f"plots/{superkingdom}/heatmap_counts_{threshold}_{rank}_level.pdf",
            gold_standard=f"gold_standard/gs_{community}.tsv",
            scores_presence=expand("benchmark/tax-class/{community}/stats/{superkingdom}_{out}_{rank}_level_{thr}.tsv",superkingdom=superkingdom,community=community,thr=threshold,out=['scores','presence'],rank=rank),
            presence_heatmap=f"benchmark/tax-class/{community}/plots/heatmap_presence_{superkingdom}_{threshold}_{rank}_level.pdf",
            pr_curve=f"benchmark/tax-class/{community}/plots/precision-recall-{superkingdom}-{rank}.pdf",
            f1_curve=f"benchmark/tax-class/{community}/plots/f1-{superkingdom}-{rank}.pdf",
            curve_table=f"benchmark/tax-class/{community}/stats/precision-recall-{superkingdom}-{rank}.tsv",
            optimal_params=f"benchmark/tax-class/{community}/stats/optimal-params-{superkingdom}-{rank}.tsv",
            l1_distance=f"benchmark/tax-class/{community}/plots/l1-distance-{superkingdom}-{rank}.pdf",
            l1_dist_table=f"benchmark/tax-class/{community}/stats/l1-distance-{superkingdom}-{rank}.tsv",
            barplots=expand("plots/{superkingdom}/barplot_{variable}_{rank}_level.pdf",superkingdom=superkingdom,rank=rank,variable=['tools','samples']),
            all_barplots=f"benchmark/tax-class/{community}/plots/barplot-{superkingdom}-{rank}.pdf",
            table_reads=f"benchmark/tax-class/{community}/stats/classified-{superkingdom}.tsv",
            barplot_reads=f"benchmark/tax-class/{community}/plots/classified-{superkingdom}.pdf",
            tab="benchmark/resources_usage/resources.tsv",
            memo="benchmark/resources_usage/memory.pdf",
            time="benchmark/resources_usage/time.pdf",
            mem_and_time="benchmark/resources_usage/mem-time.pdf"

rule linear_tax_Kraken2:
    conda: pipeline_path + "envs/benchmark.yml"

    input: "kraken2/{sample}/report.txt"

    output: "taxonomy-tables/kraken2/{sample}.tsv"

    params: NCBI_email=config['email'],
            NCBI_key=config['api_key']

    script: "scripts/kraken2-tax.py"


rule linear_tax_Kraken2X:
    conda: pipeline_path + "envs/benchmark.yml"

    input: expand("kraken2x/{sample}/report.txt",sample=list(read_naming.keys()))

    output: "taxonomy-tables/kraken2x/{sample}.tsv"

    params: NCBI_email=config['email'],
            NCBI_key=config['api_key']

    script: "scripts/kraken2-tax.py"


rule linear_tax_Bracken:
    conda: pipeline_path + "envs/benchmark.yml"

    input: "kraken2/{sample}/bracken.txt"

    output: "taxonomy-tables/bracken/{sample}.tsv"

    script: "scripts/bracken-tax.py"


rule correct_Pathseq_counts:
    conda: pipeline_path + "envs/benchmark.yml"

    input: "Pathseq/{sample}/output/scores.txt"

    output: "Pathseq/{sample}/output/correct-scores.txt"

    script: "scripts/pathseq-correct-counts.py"


rule linear_tax_Pathseq:
    conda: pipeline_path + "envs/benchmark.yml"

    input: "Pathseq/{sample}/output/correct-scores.txt"

    output: "taxonomy-tables/pathseq/{sample}.tsv"

    script: "scripts/pathseq-tax.py"


rule linear_tax_Kaiju:
    conda: pipeline_path + "envs/benchmark.yml"

    input: "kaiju/{sample}/summary.tsv"

    output: "taxonomy-tables/kaiju/{sample}.tsv"

    script: "scripts/kaiju-tax.py"


rule linear_tax_SURPI:
    conda: pipeline_path + "envs/benchmark.yml"

    input: bac="SURPI/{sample}/OUTPUT_{sample}/{sample}.NT.snap.matched.d1.fl.Bacteria.annotated.species.clx.counttable",
           vir="SURPI/{sample}/OUTPUT_{sample}/{sample}.NT.snap.matched.d16.fl.Viruses.filt.NTblastn_tru.dust.annotated.species.clx.counttable"
            #dust.annotated file because low complexity regions are substracted

    output: "taxonomy-tables/surpi/{sample}.tsv"

    log: logging_folder + f"benchmark/{community}/classification/{{sample}}-surpi.log"

    script: "scripts/surpi-tax.py"



rule linear_tax_ezVIR:
    conda: pipeline_path + "envs/benchmark.yml"

    input: hits="ezVIR/{sample}/report/ALL-RESULTS.ezv"


    output: "taxonomy-tables/ezvir/{sample}.tsv"

    params: read_len=config["samples_read_length"],
            gen_taxids=f'{ezvir_db}/genome_taxids.csv'

    script: "scripts/ezVIR-tax.py"


rule linear_tax_ganon:
    conda: pipeline_path + "envs/benchmark.yml"

    input: "ganon/{sample}/classified.rep"

    output: "taxonomy-tables/ganon/{sample}.tsv"

    params: NCBI_email=config['email'],
            NCBI_key=config['api_key']

    script: "scripts/ganon-tax.py"


rule linear_tax_centrifuge:
    conda: pipeline_path + "envs/benchmark.yml"

    input: "centrifuge/{sample}/centrifuge-k-report.txt"

    output: "taxonomy-tables/centrifuge/{sample}.tsv"

    params: NCBI_email=config['email'],
            NCBI_key=config['api_key']
    
    script: "scripts/kraken2-tax.py"


rule get_tax_table_metaphlan:
   conda: pipeline_path + "envs/benchmark.yml"

   input: "metaphlan/{sample}/profiled_{sample}.txt"

   output: "metaphlan/{sample}/profiled_{sample}.tsv"

   script: "scripts/metaphlan-tab.py"



rule linear_tax_metaphlan:
    conda: pipeline_path + "envs/benchmark.yml"

    input: "metaphlan/{sample}/profiled_{sample}.tsv"

    output: "taxonomy-tables/metaphlan/{sample}.tsv"

    params: NCBI_email=config['email'],
            NCBI_key=config['api_key']

    script: "scripts/metaphlan-tax.py"



rule merge_all_tools_out:
    input: expand("taxonomy-tables/{{tool}}/{sample}.tsv",sample=list(read_naming.keys()))

    output: "taxonomy-tables/{tool}.tsv"

    script: "scripts/cat-tax.py"



rule read_count_heatmaps:
    conda: pipeline_path + "envs/benchmark.yml"

    input: "taxonomy-tables/{tool}.tsv"

    output: f"{{tool}}/heatmap-{superkingdom}-{rank}-level.pdf"

    params: rank=config["target_rank"],
            value=config["target_value"],
            superkingdom=superkingdom

    script: "scripts/heatmap-read-counts.py"



rule plot_tools_output:
    conda: pipeline_path + "envs/benchmark.yml"

    input: expand("taxonomy-tables/{tool}/{sample}.tsv",tool=tools,sample=list(read_naming.keys()))

    output: barplot_samples=f"plots/{superkingdom}/barplot_samples_{rank}_level.pdf",
            barplot_tools=f"plots/{superkingdom}/barplot_tools_{rank}_level.pdf",
            heatmap_counts=f"plots/{superkingdom}/heatmap_counts_{threshold}_{rank}_level.pdf",
            heatmap_presence=f"plots/{superkingdom}/heatmap_presence_{rank}_level.pdf"

    params: rank=config["target_rank"],
            value=config["target_value"],
            superkingdom=superkingdom,
            threshold=threshold

    script: "scripts/visualize-tool-output.py"



rule plot_resource_usage:
    conda: pipeline_path + "envs/benchmark.yml"

    input: expand("benchmark/resources_usage/{sample}/{tool}.benchmark.txt",sample=list(read_naming.keys()),tool=tools)

    output: tab="benchmark/resources_usage/resources.tsv",
            memo="benchmark/resources_usage/memory.pdf",
            time="benchmark/resources_usage/time.pdf",
            mem_and_time="benchmark/resources_usage/mem-time.pdf"

    params: type=config["tools"]

    script: "scripts/resources-usage.py"



rule genereate_gold_standard_profile:
    conda: pipeline_path + "envs/benchmark.yml"

    input: f"gold_standard/{community}.tsv"

    output: f"gold_standard/gs_{community}.tsv"

    params: community=community

    script: "scripts/gold-standard-tax.py"



rule precision_recall_f1_score_per_tool:
    conda: pipeline_path + "envs/benchmark.yml"

    input: gold_standard=f"gold_standard/gs_{community}.tsv",
            tool_out="taxonomy-tables/{tool}.tsv"

    output: scores=f"benchmark/tax-class/{community}/stats/{{tool}}/{superkingdom}_scores_{rank}_level_{threshold}.tsv",
            presence=f"benchmark/tax-class/{community}/stats/{{tool}}/{superkingdom}_presence_{rank}_level_{threshold}.tsv"

    params: threshold=threshold,
            superkingdom=superkingdom

    script: "scripts/stats.py"



rule regroup_scores_and_presence:
    conda: pipeline_path + "envs/benchmark.yml"

    input: scores=expand("benchmark/tax-class/{community}/stats/{tool}/{superkingdom}_scores_{rank}_level_{threshold}.tsv",community=community,tool=tools,superkingdom=superkingdom,rank=rank,threshold=threshold),
           presence=expand("benchmark/tax-class/{community}/stats/{tool}/{superkingdom}_presence_{rank}_level_{threshold}.tsv",community=community,tool=tools,superkingdom=superkingdom,rank=rank,threshold=threshold),

    output: all_scores=f"benchmark/tax-class/{community}/stats/{superkingdom}_scores_{rank}_level_{threshold}.tsv",
            all_presence=f"benchmark/tax-class/{community}/stats/{superkingdom}_presence_{rank}_level_{threshold}.tsv"

    script: "scripts/concat.py"


rule presence_heatmap:
    conda: pipeline_path + "envs/benchmark.yml"

    input: f"benchmark/tax-class/{community}/stats/{superkingdom}_presence_{rank}_level_{threshold}.tsv"

    output: f"benchmark/tax-class/{community}/plots/heatmap_presence_{superkingdom}_{threshold}_{rank}_level.pdf"

    params: rank=config["target_rank"]

    script: "scripts/heatmap-presence.py"



rule barplot_counts:
    conda: pipeline_path + "envs/benchmark.yml"

    input: gold_standard=f"gold_standard/gs_{community}.tsv",
           tool_out="taxonomy-tables/{tool}.tsv"

    output: f"benchmark/tax-class/{community}/{{tool}}/{superkingdom}-barplot_{rank}_level.pdf"

    params: rank=config["target_rank"],
            superkingdom=superkingdom

    script: "scripts/barplot.py"



rule all_tools_barplot_counts:
    conda: pipeline_path + "envs/benchmark.yml"

    input: gold_standard=f"gold_standard/gs_{community}.tsv",
           tool_out=expand("taxonomy-tables/{tool}.tsv",tool=tools)

    params: rank=config["target_rank"],
            superkingdom=superkingdom

    output: all_barplots=f"benchmark/tax-class/{community}/plots/barplot-{superkingdom}-{rank}.pdf"

    script: "scripts/multi-barplot.py"


rule l1_distance:
    conda: pipeline_path + "envs/benchmark.yml"

    input: gold_standard=f"gold_standard/gs_{community}.tsv",
            all_tools=expand("taxonomy-tables/{tool}.tsv",tool=tools)

    output: l1_distance=f"benchmark/tax-class/{community}/plots/l1-distance-{superkingdom}-{rank}.pdf",
            l1_dist_table=f"benchmark/tax-class/{community}/stats/l1-distance-{superkingdom}-{rank}.tsv"

    params: rank=rank,
            superkingdom=superkingdom,
            type=config["tools"]

    script: "scripts/l1-distance.py"


rule get_precision_recall_table:
    conda: pipeline_path + "envs/benchmark.yml"

    input: gold_standard=f"gold_standard/gs_{community}.tsv",
           tool="taxonomy-tables/{tool}.tsv"

    output: aupr_table=f"benchmark/tax-class/{community}/stats/{{tool}}/aupr-{superkingdom}-{rank}.tsv"

    params: rank=rank,
            superkingdom=superkingdom,
            read_step=config["read-step"],
            max_read=config["max-read"]

    script: "scripts/precision-recall.py"


rule plot_precision_recall_f1_curves:
   conda: pipeline_path + "envs/benchmark.yml"

   input: expand("benchmark/tax-class/{community}/stats/{tool}/aupr-{superkingdom}-{rank}.tsv",superkingdom=superkingdom,community=community,tool=tools,rank=rank)

   output:  pr_curve=f"benchmark/tax-class/{community}/plots/precision-recall-{superkingdom}-{rank}.pdf",
            f1_curve=f"benchmark/tax-class/{community}/plots/f1-{superkingdom}-{rank}.pdf",
            curve_table=f"benchmark/tax-class/{community}/stats/precision-recall-{superkingdom}-{rank}.tsv",
            optimal_params=f"benchmark/tax-class/{community}/stats/optimal-params-{superkingdom}-{rank}.tsv"

   script: "scripts/plot-precision-recall.py"


rule number_of_classified_reads:
    conda: pipeline_path + "envs/benchmark.yml"

    input: gold_standard=f"gold_standard/gs_{community}.tsv",
           all_tools=expand("taxonomy-tables/{tool}.tsv",tool=tools)

    output: table=f"benchmark/tax-class/{community}/stats/classified-{superkingdom}.tsv",
            barplot=f"benchmark/tax-class/{community}/plots/classified-{superkingdom}.pdf"

    params: superkingdom=superkingdom

    script: "scripts/classified-reads.py"



if community=='qPCR':

    rule all_PCR:
        input: all_scores=f"benchmark/tax-class/{community}/stats/PCR_{superkingdom}_scores-{threshold}.tsv",
                all_presence=f"benchmark/tax-class/{community}/stats/PCR_{superkingdom}_presence-{threshold}.tsv"

    rule precision_recall_vs_qPCR:
        conda: pipeline_path + "envs/benchmark.yml"

        input: gold_standard=f"gold_standard/gs_{community}.tsv",
                tool_out="taxonomy-tables/{tool}.tsv"

        output: scores=f"benchmark/tax-class/{community}/stats/{{tool}}/PCR_{superkingdom}_scores-{threshold}.tsv",
                presence=f"benchmark/tax-class/{community}/stats/{{tool}}/PCR_{superkingdom}_presence-{threshold}.tsv"

        params: threshold=threshold,
                superkingdom=superkingdom

        script: "scripts/qPCR.py"

    rule concat_qPCR_results:
        conda: pipeline_path + "envs/benchmark.yml"

        input: scores=expand("benchmark/tax-class/{community}/stats/{tool}/PCR_{superkingdom}_scores-{threshold}.tsv",superkingdom=superkingdom,community=community,tool=tools,threshold=threshold),
               presence=expand("benchmark/tax-class/{community}/stats/{tool}/PCR_{superkingdom}_presence-{threshold}.tsv",superkingdom=superkingdom,community=community,tool=tools,threshold=threshold)

        output: all_scores=f"benchmark/tax-class/{community}/stats/PCR_{superkingdom}_scores-{threshold}.tsv",
                all_presence=f"benchmark/tax-class/{community}/stats/PCR_{superkingdom}_presence-{threshold}.tsv"

        script: "scripts/concat.py"
